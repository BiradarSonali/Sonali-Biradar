{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BiradarSonali/Sonali-Biradar/blob/main/Email_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9fcbaeb",
      "metadata": {
        "id": "b9fcbaeb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93901bdc",
      "metadata": {
        "id": "93901bdc",
        "outputId": "61d62b31-62b2-40cd-df16-3ae979f5c50d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From gort44@excite.com Mon Jun 24 17:54:21 200...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From fork-admin@xent.com Mon Jul 29 11:39:57 2...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From dcm123@btamail.net.cn Mon Jun 24 17:49:23...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...       0\n",
              "1  From gort44@excite.com Mon Jun 24 17:54:21 200...       1\n",
              "2  From fork-admin@xent.com Mon Jul 29 11:39:57 2...       1\n",
              "3  From dcm123@btamail.net.cn Mon Jun 24 17:49:23...       1\n",
              "4  From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...       0"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('spam_assassin.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "603159db",
      "metadata": {
        "id": "603159db",
        "outputId": "f9ff0652-2657-4b3f-f956-93ae82f844bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\tusha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\tusha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\tusha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\tusha\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8091676",
      "metadata": {
        "id": "e8091676"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b500da0",
      "metadata": {
        "id": "9b500da0"
      },
      "source": [
        "##### In Preprocessing step, we remove any unnecessary symbols, headers from email_address, numbers using Regular Expression. After this we remove the stop words and lemmatize the text to make more understandable for further processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b48fb734",
      "metadata": {
        "id": "b48fb734"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Removing email headers, email addresses, URLs, special symbols, and numbers to clean the text for further processing\n",
        "    text = re.sub(r'^from.*?\\n', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\b[a-zA-Z0-9._%+-]+@[a-zA-Z.-]+\\.[a-zA-Z]{2,}\\b', '', text)\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text) if word not in stop_words]\n",
        "\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a77e2b",
      "metadata": {
        "id": "58a77e2b"
      },
      "outputs": [],
      "source": [
        "data['cleaned_text'] = data['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3feab12",
      "metadata": {
        "id": "e3feab12",
        "outputId": "5525e564-565a-4b30-8c73-9c7b579b7fed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...</td>\n",
              "      <td>mon jul returnpath deliveredto received localh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From gort44@excite.com Mon Jun 24 17:54:21 200...</td>\n",
              "      <td>mon jun returnpath deliverydate tue jun receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From fork-admin@xent.com Mon Jul 29 11:39:57 2...</td>\n",
              "      <td>mon jul returnpath deliveredto received localh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From dcm123@btamail.net.cn Mon Jun 24 17:49:23...</td>\n",
              "      <td>mon jun returnpath deliverydate mon jun receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...</td>\n",
              "      <td>mon aug returnpath deliveredto received localh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0  From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...   \n",
              "1  From gort44@excite.com Mon Jun 24 17:54:21 200...   \n",
              "2  From fork-admin@xent.com Mon Jul 29 11:39:57 2...   \n",
              "3  From dcm123@btamail.net.cn Mon Jun 24 17:49:23...   \n",
              "4  From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  mon jul returnpath deliveredto received localh...  \n",
              "1  mon jun returnpath deliverydate tue jun receiv...  \n",
              "2  mon jul returnpath deliveredto received localh...  \n",
              "3  mon jun returnpath deliverydate mon jun receiv...  \n",
              "4  mon aug returnpath deliveredto received localh...  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[['text', 'cleaned_text']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfa4ada6",
      "metadata": {
        "id": "cfa4ada6"
      },
      "source": [
        "#### We use TF-IDF Vectorizer to convert text into vector form which can processed by model for prediction. I have used N-Grams techniques including both 1gram and 2gram approach to form the vectors to capture text patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcbf2ebf",
      "metadata": {
        "id": "dcbf2ebf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_text'], data['target'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Using TF-IDF with n-grams (up to bigrams here)\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.9, min_df=5)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995ea6d3",
      "metadata": {
        "id": "995ea6d3",
        "outputId": "c2153d78-7578-4e6f-83c4-276e049e1f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy: 0.9752731454859115\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98      1172\n",
            "           1       1.00      0.92      0.96       567\n",
            "\n",
            "    accuracy                           0.98      1739\n",
            "   macro avg       0.98      0.96      0.97      1739\n",
            "weighted avg       0.98      0.98      0.98      1739\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_tfidf, y_train)\n",
        "y_pred_nb = nb_classifier.predict(X_test_tfidf)\n",
        "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55998085",
      "metadata": {
        "id": "55998085",
        "outputId": "d258dc3b-50e9-4f42-8384-62e059ee697e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.9907993099482462\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      1172\n",
            "           1       1.00      0.97      0.99       567\n",
            "\n",
            "    accuracy                           0.99      1739\n",
            "   macro avg       0.99      0.99      0.99      1739\n",
            "weighted avg       0.99      0.99      0.99      1739\n",
            "\n"
          ]
        }
      ],
      "source": [
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train_tfidf, y_train)\n",
        "y_pred_logreg = logreg.predict(X_test_tfidf)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_logreg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa50ce0c",
      "metadata": {
        "id": "fa50ce0c",
        "outputId": "84272fc5-0ecf-4e4b-8e11-8855aa25ec55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Accuracy: 0.9953996549741231\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      1172\n",
            "           1       1.00      0.99      0.99       567\n",
            "\n",
            "    accuracy                           1.00      1739\n",
            "   macro avg       1.00      0.99      0.99      1739\n",
            "weighted avg       1.00      1.00      1.00      1739\n",
            "\n"
          ]
        }
      ],
      "source": [
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm = svm.predict(X_test_tfidf)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feb54608",
      "metadata": {
        "id": "feb54608",
        "outputId": "6b5003b3-dbb6-459d-f4a6-b6d4d55e2467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 0.9913743530764807\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      1172\n",
            "           1       0.99      0.98      0.99       567\n",
            "\n",
            "    accuracy                           0.99      1739\n",
            "   macro avg       0.99      0.99      0.99      1739\n",
            "weighted avg       0.99      0.99      0.99      1739\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "rf.fit(X_train_tfidf, y_train)\n",
        "y_pred_rf = rf.predict(X_test_tfidf)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6098c5e6",
      "metadata": {
        "id": "6098c5e6"
      },
      "source": [
        "##### From the above analysis, we can say that Support Vector Classifier and Random Forest Classifier are the two best models for classification which are giving almost 99% accuracy"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}